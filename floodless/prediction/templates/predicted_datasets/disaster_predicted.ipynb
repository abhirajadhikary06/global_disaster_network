{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'draught_predicted_final.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      4\u001b[39m csv_files = [\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdraught_predicted_final.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mearthquake_predicted_final.csv\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mwildfire_predicted_final.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m ]\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Read and concatenate all CSV files\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m dataframes = [\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m csv_files]\n\u001b[32m     15\u001b[39m combined_df = pd.concat(dataframes, ignore_index=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Display the combined DataFrame\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\Floodless\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\Floodless\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\Floodless\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\Floodless\\venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Abhiraj\\OpenSource\\Floodless\\venv\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'draught_predicted_final.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV file names\n",
    "csv_files = [\n",
    "    \"draught_predicted_final.csv\",\n",
    "    \"earthquake_predicted_final.csv\",\n",
    "    \"flood_predicted_final.csv\",\n",
    "    \"storm_predicted_final.csv\",\n",
    "    \"volcano_predicted_final.csv\",\n",
    "    \"wildfire_predicted_final.csv\"\n",
    "]\n",
    "\n",
    "# Read and concatenate all CSV files\n",
    "dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_df)\n",
    "\n",
    "# Optionally save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(\"combined_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total Affected\n",
      "0   15,829,481.0\n",
      "1   04,938,793.5\n",
      "2   01,397,655.0\n",
      "3   000284,106.5\n",
      "4   01,384,673.9\n"
     ]
    }
   ],
   "source": [
    "combined_df['Total Affected'] = combined_df['Total Affected'].apply(lambda x: f\"{x:,.1f}\".zfill(12))\n",
    "print(combined_df[['Total Affected']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year                                Country  \\\n",
      "0  2026  Democratic People's Republic of Korea   \n",
      "1  2026                            El Salvador   \n",
      "2  2026                                  Kenya   \n",
      "3  2026            United Republic of Tanzania   \n",
      "4  2026                                  Italy   \n",
      "\n",
      "                                Location  Total Affected   Magnitude  \n",
      "0                         Hwanghae-namdo      15829481.0  185275.700  \n",
      "1                               Usulutan       4938793.5  137362.480  \n",
      "2                                 Kilifi       1397655.0  107761.336  \n",
      "3  Ngorongoro district (Arusha province)        284106.5  229979.190  \n",
      "4                                Sicilia       1384673.9  148570.280  \n"
     ]
    }
   ],
   "source": [
    "# Remove commas and convert 'Total Affected' column to numeric\n",
    "combined_df['Total Affected'] = combined_df['Total Affected'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "print(combined_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='final_dataset.csv' target='_blank'>final_dataset.csv</a><br>"
      ],
      "text/plain": [
       "c:\\Abhiraj\\OpenSource\\Floodless\\floodless\\prediction\\templates\\predicted_datasets\\final_dataset.csv"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(\"final_dataset.csv\", index=False)\n",
    "\n",
    "# Provide a download link\n",
    "FileLink(\"final_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Democratic People's Republic of Korea\", 'El Salvador', 'Kenya', 'United Republic of Tanzania', 'Italy', 'Democratic Republic of the Congo', 'Armenia', 'Guinea-Bissau', 'Paraguay', 'Sri Lanka', 'Türkiye', 'Indonesia', 'Republic of Korea', 'Chile', 'Ecuador', 'Pakistan', 'Rwanda', 'China', 'Syrian Arab Republic', 'Guatemala', 'Peru', 'Comoros', 'Japan', 'Serbia', 'Greece', 'Croatia', 'Iran (Islamic Republic of)', 'Viet Nam', 'Austria', 'Montenegro', 'Colombia', 'India', 'Malaysia', 'Mexico', 'United States of America', 'Nepal', 'Yemen', 'Somalia', 'Philippines', 'Ghana', 'Romania', 'Algeria', 'Uruguay', 'Sudan', 'South Africa', 'Haiti', 'Panama', 'Honduras', 'Cuba', 'Mozambique', 'Afghanistan', 'Russian Federation', 'Myanmar', 'Nigeria', 'Argentina', 'Senegal', 'Costa Rica', 'Côte d’Ivoire', 'Brazil', 'Oman', 'Bangladesh', 'Bulgaria', 'France', 'Madagascar', 'North Macedonia', 'Guinea', 'Bolivia (Plurinational State of)', 'Iraq', 'Papua New Guinea', 'Bosnia and Herzegovina', 'Mali', 'Ethiopia', 'Belarus', 'Angola', 'Togo', 'Cyprus', 'Malawi', 'Zambia', 'Slovenia', 'Ireland', 'Australia', 'Thailand', 'Portugal', 'Taiwan (Province of China)', 'Germany', 'Burundi', 'Vanuatu', 'Switzerland', 'New Zealand', 'Jamaica', 'Puerto Rico', 'Zimbabwe', 'Lebanon', 'Bhutan', 'Nicaragua', 'Saint Vincent and the Grenadines', 'Central African Republic', 'Czechia', 'Poland', 'Canada']\n"
     ]
    }
   ],
   "source": [
    "distinct_countries = combined_df['Country'].unique().tolist()\n",
    "print(distinct_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Year                   Country  \\\n",
      "0     2026                   Türkiye   \n",
      "1     2026                 Indonesia   \n",
      "2     2026         Republic of Korea   \n",
      "3     2026                     Chile   \n",
      "4     2026               El Salvador   \n",
      "...    ...                       ...   \n",
      "2423  2033  United States of America   \n",
      "2424  2033                 Guatemala   \n",
      "2425  2033                    Canada   \n",
      "2426  2033  United States of America   \n",
      "2427  2033                   Ecuador   \n",
      "\n",
      "                                               Location  Total Affected  \\\n",
      "0                                                 Özalp     4746.452637   \n",
      "1     Buol district (Sulawesi Tengah province) Goron...    13139.191406   \n",
      "2                                                Kyonju     3731.136719   \n",
      "3                                             Tocopilla     9131.350586   \n",
      "4                                           San Lorenzo     6617.301758   \n",
      "...                                                 ...             ...   \n",
      "2423                  Fallbrok area (San Diego district     1183.289795   \n",
      "2424                                          Guatemala     1121.361328   \n",
      "2425                                    Quebec province      186.448349   \n",
      "2426                                              Texas     3015.392822   \n",
      "2427                                              Azuay     1114.581787   \n",
      "\n",
      "          Magnitude Disaster Type  \n",
      "0          6.150232       Drought  \n",
      "1          6.114689       Drought  \n",
      "2          6.217031       Drought  \n",
      "3          7.069474       Drought  \n",
      "4          5.717484       Drought  \n",
      "...             ...           ...  \n",
      "2423  164420.400000      Wildfire  \n",
      "2424   55344.130000      Wildfire  \n",
      "2425   89661.770000      Wildfire  \n",
      "2426  106507.240000      Wildfire  \n",
      "2427   18491.291000      Wildfire  \n",
      "\n",
      "[2428 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of CSV file names\n",
    "csv_files = [\n",
    "    \"drought_predicted_final.csv\",\n",
    "    \"earthquake_predicted_final.csv\",\n",
    "    \"flood_predicted_final.csv\",\n",
    "    \"storm_predicted_final.csv\",\n",
    "    \"volcano_predicted_final.csv\",\n",
    "    \"wildfire_predicted_final.csv\"\n",
    "]\n",
    "\n",
    "# Read and concatenate all CSV files\n",
    "dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_df)\n",
    "\n",
    "# Optionally save the combined DataFrame to a new CSV file\n",
    "combined_df.to_csv(\"final_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='final_predictions.csv' target='_blank'>final_predictions.csv</a><br>"
      ],
      "text/plain": [
       "c:\\Abhiraj\\OpenSource\\Floodless\\floodless\\prediction\\templates\\predicted_datasets\\final_predictions.csv"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Save the combined DataFrame to a CSV file\n",
    "combined_df.to_csv(\"final_predictions.csv\", index=False)\n",
    "\n",
    "# Provide a download link\n",
    "FileLink(\"final_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
